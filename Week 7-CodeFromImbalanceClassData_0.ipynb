{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Wayn9goRznv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, recall_score, \\\n",
    "precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guA3Y5AMRzn0"
   },
   "source": [
    "# 1. Some subroutines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NVinTqASRzn2"
   },
   "outputs": [],
   "source": [
    "def get_banking():\n",
    "    # https://www.kaggle.com/code/rashmiranu/banking-dataset-eda-and-binary-classification/notebook\n",
    "    mydata = pd.read_csv('/Users/nengkuantu/Downloads/new_train.csv')\n",
    "    mydata = mydata[['age',  'duration', 'campaign', 'pdays', 'previous', 'y']]\n",
    "    mydata['y'] = mydata['y'].map(lambda x: 0 if x == \"no\" else 1)\n",
    "    mydata.rename({'y': 'label'}, axis = 1, inplace=True)\n",
    "    \n",
    "    \n",
    "    X = mydata.drop(columns=['label']).values\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    ss = StandardScaler()\n",
    "    X = ss.fit_transform(X)\n",
    "    \n",
    "    \n",
    "    y = mydata['label'].values\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGzBkOQiRzn4"
   },
   "outputs": [],
   "source": [
    "def get_bcw() :\n",
    "    bcw = pd.read_csv('~/Downloads/wdbc.data' , header=None)\n",
    "    column_names = ['id','malignant',\n",
    "                'nucleus_mean','nucleus_se','nucleus_worst',\n",
    "                'texture_mean','texture_se','texture_worst',\n",
    "                'perimeter_mean','perimeter_se','perimeter_worst',\n",
    "                'area_mean','area_se','area_worst',\n",
    "                'smoothness_mean','smoothness_se','smoothness_worst',\n",
    "                'compactness_mean','compactness_se','compactness_worst',\n",
    "                'concavity_mean','concavity_se','concavity_worst',\n",
    "                'concave_pts_mean','concave_pts_se','concave_pts_worst',\n",
    "                'symmetry_mean','symmetry_se','symmetry_worst',\n",
    "                'fractal_dim_mean','fractal_dim_se','fractal_dim_worst']\n",
    "\n",
    "    bcw.columns = column_names\n",
    "    \n",
    "    bcw['malignant'] = bcw['malignant'].map(lambda x: 0 if x == \"B\" else 1)\n",
    "\n",
    "    # make a copy for two purposes:\n",
    "    # 1. keep the original data intake for futural reference.\n",
    "    # 2. use the same dataset name \"mydata\" for later processing\n",
    "    # so that we use the same code for different dataset.\n",
    "\n",
    "    #     X = mydata[['nucleus_mean','texture_mean','perimeter_mean']]\n",
    "    X = bcw.drop(columns=['id', 'malignant']).values\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    ss = StandardScaler()\n",
    "    X = ss.fit_transform(X)\n",
    "    \n",
    "    \n",
    "    y = bcw['malignant'].values\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIARHrJRRzn5"
   },
   "outputs": [],
   "source": [
    "def evaluate(pred, expect) :\n",
    "    ans = pred - expect\n",
    "    error_sum = ans.sum()\n",
    "    n_errors = abs(ans).sum()\n",
    "    accuracy = 1 - n_errors / expect.shape[0]\n",
    "    \n",
    "    return round(accuracy, 3) , n_errors, error_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hk9hkHGpRzn6"
   },
   "outputs": [],
   "source": [
    "def evaluateConfusion(expect, pred) :\n",
    "    \n",
    "    ConfusionMatrix = confusion_matrix(expect, pred)\n",
    "    f1 = f1_score(expect, pred)\n",
    "    accuracy = accuracy_score(expect, pred)\n",
    "    recall = recall_score(expect, pred)\n",
    "    precision = precision_score(expect, pred)\n",
    "    \n",
    "    return f1, accuracy, recall, precision, ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACo8KkcwRzn7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRRS3HA_Rzn8"
   },
   "source": [
    "# 2. get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AjRK42IGRzn8"
   },
   "outputs": [],
   "source": [
    "X, y = get_banking()   # X: feature vector, y label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKl3W40vRzn9"
   },
   "source": [
    "# 3. Split Data into Training and Testing\n",
    "--------\n",
    "Choose 3.1  and 3.2 to get the type of split data you want to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYzW0nQVRzn-"
   },
   "source": [
    "# 3.1 Original Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjnNe-V9Rzn-",
    "outputId": "bd9540d6-e2f6-4405-8b0f-3f4db0e337e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32950, 5)\n",
      "(32950,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[[ 0.86373877 -0.12019627  0.52298128  0.19658384 -0.35012691]\n",
      " [ 3.65126795  3.43617293 -0.56702251  0.19658384 -0.35012691]\n",
      " [ 1.82495573  0.42426417 -0.20368791  0.19658384 -0.35012691]]\n",
      "[0 0 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(type(X))\n",
    "print(type(y))\n",
    "# numpy array does not have column names.  \n",
    "# We can only use the slice [row_start:row_end:step_row, col_start:col_end:step_col]\n",
    "# to select rows and cols we want\n",
    "# be aware that row_end and col_end are not inclusive\n",
    "# the format of the output will be discussed in another lecture.\n",
    "print(X[0:6:2])\n",
    "print(y[0:40:4])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=2018) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASbJ59XzRzoA"
   },
   "source": [
    "# 3.2 Data Split to Get Imbalanced Labels in Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYXy8-AORzoA"
   },
   "outputs": [],
   "source": [
    "def GetImbalancedLabelData(DF_orig, label_ratio) :\n",
    "    import copy as copy\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    DF = copy.copy(DF_orig)\n",
    "    DF1 = DF[DF.malignant == 1]\n",
    "    DF0 = DF[DF.malignant == 0]\n",
    "    \n",
    "    Test_Size= 0.25  # intended test size.  The actual size depend on how the train data is arranged.\n",
    "    # Simple implementation : \n",
    "    #      split both DF0 with Test_Size and DF1 with label_ratio \n",
    "    #      This method can not produce the right label_ratio for training set. \n",
    "#     TestSizeFrom0 =  Test_Size\n",
    "    # instead , the following 2 statement, can split the training data in the precise label_ratio.\n",
    "    max_train0_size = min(DF0.shape[0], DF1.shape[0])  \n",
    "    TestSizeFrom0 = 1 -  min(max_train0_size, DF0.shape[0] * (1- Test_Size) ) / DF0.shape[0]\n",
    "    \n",
    "    \n",
    "    DF0_train, DF0_test = train_test_split(DF0, test_size = TestSizeFrom0, random_state=2018)\n",
    "    DF1_train, DF1_test = train_test_split(DF1, test_size =  (1 - label_ratio), random_state=2018)\n",
    "    \n",
    "    DF_train = pd.concat((DF0_train, DF1_train) )\n",
    "    DF_test = pd.concat((DF0_test, DF1_test) )\n",
    "    \n",
    "    y_train = DF_train.malignant.values\n",
    "    X_train = DF_train.drop(columns=[ 'malignant']).values\n",
    "    y_test = DF_test.malignant.values\n",
    "    X_test = DF_test.drop(columns=[ 'malignant']).values\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qupy8NGRRzoB"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = GetImbalancedLabelData(bcw, 0.8)\n",
    "print(y_train.sum(), y_train.shape,  y_test.sum(), y_test.shape,)\n",
    "print(y_train.sum()/( y_train.shape[0] - y_train.sum() )  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qSm-L1vvRzoB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZoGdHdbKRzoC"
   },
   "source": [
    "# 4. Collect results with various labelratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YIJSggbsRzoC"
   },
   "outputs": [],
   "source": [
    "def RunAll(X_train, X_test, y_train, y_test, default = 1) :\n",
    "    \n",
    "    # default: 1 for default class_weight (or default weights if KNN)\n",
    "    # default: 0 forclass_weight = balanced (or weights = 'distance' if KNN)\n",
    "        \n",
    "    results = []\n",
    "    \n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    if default :\n",
    "        DT = DecisionTreeClassifier()\n",
    "    else:\n",
    "        DT = DecisionTreeClassifier(class_weight='balanced') # default:None, other: balanced\n",
    "    model = DT\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    results = results + [['DT', default ] + list( evaluate(pred, y_test))]\n",
    "    \n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    if default :\n",
    "        RF = RandomForestClassifier(n_estimators =50)\n",
    "    else:\n",
    "        RF = RandomForestClassifier(n_estimators =50, class_weight='balanced') # default:None, other: balanced    \n",
    "    model = RF\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    results = results + [['RF', default] + list( evaluate(pred, y_test))]\n",
    "    \n",
    "        \n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    if default :\n",
    "        KNN = KNeighborsClassifier()\n",
    "    else:\n",
    "        KNN = KNeighborsClassifier(weights = 'distance') # default:uniform, other: distance    \n",
    "    model = KNN\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    results = results + [['KNN', default] + list( evaluate(pred, y_test))]\n",
    "    \n",
    "        \n",
    "    from sklearn.svm import SVC\n",
    "    if default :\n",
    "        SVM = SVC(gamma='scale')\n",
    "    else:\n",
    "        SVM = SVC(gamma='scale', class_weight='balanced') # default:None, other: balanced\n",
    "    model = SVM\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    results = results + [['SVM', default ] + list( evaluate(pred, y_test))]\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    if default :\n",
    "        LogR = LogisticRegression(solver='lbfgs')\n",
    "    else:\n",
    "        LogR = LogisticRegression(solver='lbfgs', class_weight='balanced') # default:None, other: balanced\n",
    "    model = LogR\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    results = results + [['LogR', default] + list( evaluate(pred, y_test))]\n",
    "\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9akdRF5TRzoD",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Default = RunAll(X_train, X_test, y_train, y_test, default = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yM0Y7dtnRzoE",
    "outputId": "80beb6bc-65cf-4850-cf9a-7478bca3a2cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['DT', 1, 0.869, 1076, -14],\n",
       " ['RF', 1, 0.893, 878, -240],\n",
       " ['KNN', 1, 0.901, 819, -329],\n",
       " ['SVM', 1, 0.907, 764, -478],\n",
       " ['LogR', 1, 0.908, 754, -472]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzhedxpFRzoE",
    "outputId": "30d3bfc3-7ee2-4f79-d535-949f13f0ec1a",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>weight</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>N_erros</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DT</td>\n",
       "      <td>1</td>\n",
       "      <td>0.869</td>\n",
       "      <td>1076</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>0.893</td>\n",
       "      <td>878</td>\n",
       "      <td>-240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.901</td>\n",
       "      <td>819</td>\n",
       "      <td>-329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>1</td>\n",
       "      <td>0.907</td>\n",
       "      <td>764</td>\n",
       "      <td>-478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogR</td>\n",
       "      <td>1</td>\n",
       "      <td>0.908</td>\n",
       "      <td>754</td>\n",
       "      <td>-472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  weight  accuracy  N_erros  bias\n",
       "0    DT       1     0.869     1076   -14\n",
       "1    RF       1     0.893      878  -240\n",
       "2   KNN       1     0.901      819  -329\n",
       "3   SVM       1     0.907      764  -478\n",
       "4  LogR       1     0.908      754  -472"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DefaultDF = pd.DataFrame(Default, columns = ['model', 'weight', 'accuracy', 'N_erros', 'bias'])\n",
    "DefaultDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QUHgK8jqRzoF",
    "outputId": "70b7507e-e438-4f4a-9fa7-dc5a53ba89d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>weight</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>N_erros</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.865</td>\n",
       "      <td>1112</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>0</td>\n",
       "      <td>0.890</td>\n",
       "      <td>910</td>\n",
       "      <td>-234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.889</td>\n",
       "      <td>915</td>\n",
       "      <td>-205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0</td>\n",
       "      <td>0.829</td>\n",
       "      <td>1412</td>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogR</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842</td>\n",
       "      <td>1305</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  weight  accuracy  N_erros  bias\n",
       "0    DT       0     0.865     1112     8\n",
       "1    RF       0     0.890      910  -234\n",
       "2   KNN       0     0.889      915  -205\n",
       "3   SVM       0     0.829     1412   994\n",
       "4  LogR       0     0.842     1305   775"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Weight = RunAll(X_train, X_test, y_train, y_test, default = 0)\n",
    "WeightDF =  pd.DataFrame(Weight, columns = ['model', 'weight', 'accuracy', 'N_erros', 'bias'])\n",
    "WeightDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3HGFT5rRzoF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "My6NInCrRzoF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0Oqv8SnRzoG"
   },
   "source": [
    "## 5. Confusion Matrix\n",
    "-----\n",
    "![image.png](attachment:image.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9MbA3djCRzoG"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, recall_score, \\\n",
    "precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5lauExduRzoG"
   },
   "outputs": [],
   "source": [
    "def RunAllConfusion(X_train, X_test, y_train, y_test, default = 1) :\n",
    "    \n",
    "    # default: 1 for default class_weight (or default weights if KNN)\n",
    "    # default: 0 forclass_weight = balanced (or weights = 'distance' if KNN)\n",
    "        \n",
    "    results = []\n",
    "    \n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    if default :\n",
    "        DT = DecisionTreeClassifier()\n",
    "    else:\n",
    "        DT = DecisionTreeClassifier(class_weight='balanced') # default:None, other: balanced\n",
    "    model = DT\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    results = results + [['DT' ] + [evaluateConfusion(y_test, pred)]]\n",
    "    \n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    if default :\n",
    "        RF = RandomForestClassifier(n_estimators =50)\n",
    "    else:\n",
    "        RF = RandomForestClassifier(n_estimators =50, class_weight='balanced') # default:None, other: balanced    \n",
    "    model = RF\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    results = results + [['RF']  + [evaluateConfusion(y_test, pred)]]\n",
    "    \n",
    "        \n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    if default :\n",
    "        KNN = KNeighborsClassifier()\n",
    "    else:\n",
    "        KNN = KNeighborsClassifier(weights = 'distance') # default:uniform, other: distance    \n",
    "    model = KNN\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    results = results + [['KNN']  + [evaluateConfusion(y_test, pred)]]\n",
    "    \n",
    "        \n",
    "    from sklearn.svm import SVC\n",
    "    if default :\n",
    "        SVM = SVC(gamma='scale')\n",
    "    else:\n",
    "        SVM = SVC(gamma='scale', class_weight='balanced') # default:None, other: balanced\n",
    "    model = SVM\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    results = results + [['SVM']  + [evaluateConfusion(y_test, pred)]]\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    if default :\n",
    "        LogR = LogisticRegression(solver='lbfgs')\n",
    "    else:\n",
    "        LogR = LogisticRegression(solver='lbfgs', class_weight='balanced') # default:None, other: balanced\n",
    "    model = LogR\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    results = results + [['LogR']  + [evaluateConfusion(y_test, pred)]]\n",
    "\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uv1dOWY4RzoH",
    "outputId": "97f9eb5a-7440-474c-f2e9-45c8a2bfd046",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['DT',\n",
       "  (0.3982251802551304,\n",
       "   0.8682932750667638,\n",
       "   0.3949394939493949,\n",
       "   0.4015659955257271,\n",
       "   array([[6794,  535],\n",
       "          [ 550,  359]]))],\n",
       " ['RF',\n",
       "  (0.44529262086513993,\n",
       "   0.8941490653071134,\n",
       "   0.385038503850385,\n",
       "   0.5279034690799397,\n",
       "   array([[7016,  313],\n",
       "          [ 559,  350]]))],\n",
       " ['KNN',\n",
       "  (0.44996642041638685,\n",
       "   0.9005826656955572,\n",
       "   0.36853685368536854,\n",
       "   0.5775862068965517,\n",
       "   array([[7084,  245],\n",
       "          [ 574,  335]]))],\n",
       " ['SVM',\n",
       "  (0.42985074626865666,\n",
       "   0.9072590434571498,\n",
       "   0.31683168316831684,\n",
       "   0.6682134570765661,\n",
       "   array([[7186,  143],\n",
       "          [ 621,  288]]))],\n",
       " ['LogR',\n",
       "  (0.4398216939078752,\n",
       "   0.9084729303228939,\n",
       "   0.3256325632563256,\n",
       "   0.6773455377574371,\n",
       "   array([[7188,  141],\n",
       "          [ 613,  296]]))]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Default = RunAllConfusion(X_train, X_test, y_train, y_test, default = 1)\n",
    "Default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-8kskIgRzoH",
    "outputId": "fef50b74-7186-4a80-aee2-5011c28a49ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9084729303228939\n"
     ]
    }
   ],
   "source": [
    "print((7188+296)/(7188+296+141+613))  # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tkqVL6b8RzoI",
    "outputId": "3a7795f1-424a-46c7-b4b2-e8ca11c10740"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6773455377574371\n"
     ]
    }
   ],
   "source": [
    "print(296/(296+141))  # precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jYOHwQeZRzoI",
    "outputId": "cbc733de-ca2f-4f05-99ca-dc00b03fc58b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3256325632563256\n"
     ]
    }
   ],
   "source": [
    "print(296/ (296 + 613) )  # recall or sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJVwfVJGRzoI",
    "outputId": "0c0fea81-505f-4eb8-d5a2-731f5b7b1300"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4398216939078752"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*(0.3256325632563256*0.6773455377574371)/(0.3256325632563256+0.6773455377574371)  # f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZqmgwS8-RzoJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2Y1-UKjRzoJ",
    "outputId": "7965bd59-6f1d-487b-824b-da7d541e3dd5",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['DT',\n",
       "  (0.39113573407202223,\n",
       "   0.8665938334547221,\n",
       "   0.38833883388338836,\n",
       "   0.3939732142857143,\n",
       "   array([[6786,  543],\n",
       "          [ 556,  353]]))],\n",
       " ['RF',\n",
       "  (0.4249363867684478,\n",
       "   0.8902646273367322,\n",
       "   0.36743674367436746,\n",
       "   0.5037707390648567,\n",
       "   array([[7000,  329],\n",
       "          [ 575,  334]]))],\n",
       " ['KNN',\n",
       "  (0.43273403595784254,\n",
       "   0.8889293517844137,\n",
       "   0.38393839383938394,\n",
       "   0.49573863636363635,\n",
       "   array([[6974,  355],\n",
       "          [ 560,  349]]))],\n",
       " ['SVM',\n",
       "  (0.4978662873399715,\n",
       "   0.8285991745569313,\n",
       "   0.77007700770077,\n",
       "   0.3678402522333158,\n",
       "   array([[6126, 1203],\n",
       "          [ 209,  700]]))],\n",
       " ['LogR',\n",
       "  (0.49672194369456224,\n",
       "   0.8415877640203933,\n",
       "   0.7084708470847084,\n",
       "   0.3824228028503563,\n",
       "   array([[6289, 1040],\n",
       "          [ 265,  644]]))]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Weight = RunAllConfusion(X_train, X_test, y_train, y_test, default = 0)\n",
    "Weight\n",
    "# WeightDF =  pd.DataFrame(Weight, columns = ['model', 'weight', 'accuracy', 'N_erros', 'bias'])\n",
    "# WeightDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V7B7Zy_eRzoJ",
    "outputId": "bb298a11-97ff-4f55-c173-f40b88914cc4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49672194369456224"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*(0.7084708470847084*0.3824228028503563)/(0.7084708470847084+0.3824228028503563)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TcP8veKsRzoJ",
    "outputId": "dc7c75bb-e4a8-4191-cce3-7e29a5d8cba8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KNN', array([[6974,  560],\n",
       "        [ 355,  349]])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Weight[1:3][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PfI7QHoyRzoK",
    "outputId": "b1d605f7-52cb-4973-95be-e4edee40f040"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      DT\n",
      "1      RF\n",
      "2     KNN\n",
      "3     SVM\n",
      "4    LogR\n",
      "Name: 0, dtype: object \n",
      " 0     [[6783, 558], [546, 351]]\n",
      "1     [[6989, 559], [340, 350]]\n",
      "2     [[6974, 560], [355, 349]]\n",
      "3    [[6126, 209], [1203, 700]]\n",
      "4    [[6289, 265], [1040, 644]]\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "WeightDF  = pd.DataFrame(Weight)\n",
    "print( WeightDF.iloc[:, 0], '\\n', WeightDF.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98i91gANRzoK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yloHrgCORzoK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D4uETQjbRzoK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s0Dlv6DJRzoL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OiY16FAJRzoL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZHJxBybRzoL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QaCXIHb0RzoL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
